<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Econometria I</title>
    <link rel="stylesheet" href="..\static\styles.css">
    <!-- google tag manager -->
    <!-- Google Tag Manager -->
    <script>
        (
            function(w,d,s,l,i){
                w[l]=w[l]||[];
                w[l].push({
                    'gtm.start': new Date().getTime(),
                    event:'gtm.js'
                });
                var f=d.getElementsByTagName(s)[0],
                j=d.createElement(s),
                dl=l!='dataLayer'?'&l='+l:'';
                j.async=true;
                j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;
                f.parentNode.insertBefore(j,f);
    }) (window,document,'script','dataLayer','GTM-PDCR7TXH');
    </script>
    <!-- End Google Tag Manager -->
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NLW3B6G2F5"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NLW3B6G2F5');
    </script>
    <!-- icones -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <!-- formulas e equações -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PDCR7TXH"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
    <header>
        <h1>Econometria I</h1>
    </header>
    <div class="container">
        <nav class="side-menu left">
            <ul>
                <li class="menu-item">
                    <a href="#resumoP1">Resumo P1</a>
                    <ul class="submenu">
                        <li><a href="#regressao-simples">Regressão Simples</a></li>
                        <li><a href="#teste-hipotese">Teste de Hipótese</a></li>
                        <li><a href="#qualidade-modelo">Qualidade do Modelo</a></li>
                    </ul>
                </li>
                <li class="menu-item">
                    <a href="#resumoP2">Resumo P2</a>
                    <ul class="submenu">
                        <li><a href="#regressao-multipla">Regressão Múltipla</a></li>
                        <li><a href="#mr-mi">Modelo R e I</a></li>
                        <li><a href="#estatistica-f">Estatística-F</a></li>
                        <li><a href="#r2-ajustado">R Ajustado</a></li>
                        <li><a href="#dummys">Dummys</a></li>
                    </ul>
                </li>
                <li class="menu-item">
                    <a href="#">Provas</a>
                    <ul class="submenu">
                        <li><a href="#">P1 2023.2</a></li>
                        <li><a href="#">P2 2023.2</a></li>
                        <li><a href="#">P1 2023.1</a></li>
                        <li><a href="#">P2 2023.1</a></li>
                        <li><a href="#">P1 2022.2</a></li>
                        <li><a href="#">P2 2022.2</a></li>
                    </ul>
                </li>
                <li class="menu-item">
                    <a href="">Listas</a>
                </li>
            </ul>
        </nav>
        <main>
            <section id="introducao">
                <h2>Povão,</h2>
                <p>O objetivo desse site é nivelar o conhecimento necessário para passar no curso de Econometria I <b>noturno</b> de Ciências Econômicas na UFF. Em alguns momentos, propositalmente, vamos preferir usar uma linguagem mais simples ao invés do jargão estatístico para facilitar a compreensão. Além disso, vamos relembrar alguns conceitos que você talvez não se lembre de estatística I e II.</p>
                <p>Se você está procurando pelo conteúdo do curso da manhã ou deseja fornecer um feedback, envie um e-mail para <a href="mailto:jggmartins@id.uff.br;joaostrauss@id.uff.br?subject=Site%20de%20Econometria%20I">jggmartins@id.uff.br</a> (João Gabriel - desenvolvedor do site) ou <a href="mailto:joaostrauss@id.uff.br;jggmartins@id.uff.br?subject=Site%20de%20Econometria%20I">joaostrauss@id.uff.br</a> (João Strauss - monitor do curso de econometria I).</p>
            </section>
            <section id="resumoP1">

                <section id="intro-p1">
                    <h2>Resumo P1</h2>
                    <p>Na primeira parte do curso (até a P1), vamos nos restringir a um modelo de regressão com dois coeficientes (\(\beta_0\) e \(\beta_1\)) e uma variável explicativa (\(X_1\)) - modelo de regressão simples. Eu diria que 70% da P1 consiste em conseguir resolver esse problema, não sugiro que você ignore os outros 30%, mas nessa seção vamos tratar de explicar o principal problema da P1.</p>
                </section>

                <section id="regressao-simples">
                    <h3>Modelo Simples de Regressão Linear</h3>
                    <p>$$ Y = \beta_0 + \beta_1X_1 + u $$</p>
                    <p>\(Y\) = Variável dependente</p>
                    <p>\(\beta_0\) = Coeficiente do intercepto</p>
                    <p>\(\beta_1\) = Coeficiente da variável explicativa</p>
                    <p>\(X_1\) = Variável explicativa ou variável independente</p>
                    <p>\(u\) = residual/termo de erro</p>
                    <p>O exercício consiste em encontrar a melhor variável explicativa para a variável dependente (\(Y\)). Quanto maior a correlação entre as duas variáveis, maior será o valor de \(\beta_1\), ou seja, \(\beta_1\) representa o impacto que uma alteração unitária em \(X_1\) pode causar em \(Y\). Logo, quanto maior \(\beta_1\), maior será a parcela de Y que será explicada pela variável explicativa (\(X_1\)). Por sua vez, o “termo de erro” ou “residual” (\(u\)) serve para representar todo o restante que não pode ser explicado pela variável explicativa e pelo coeficiente de intercepto usado no modelo.</p>
                    <p>Porém, nunca conseguimos ter 100% de certeza de que aquele coeficiente (\(\beta_1\)) (por exemplo: 0,81) de fato impacta a variável explicativa (\(Y\)) na magnitude informada, isso porque no mundo real raramente teremos acesso aos dados populacionais, apenas a uma amostra desses dados. Por exemplo, digamos que a variável dependente (\(Y\)) seja o preço da corrida na Uber, e vamos considerar que \(X_1\) seja a distância entre o ponto de partida e o ponto de chegada em Kms. Logo, seria impossível montar um banco de dados com todas as distâncias entre dois pontos do planeta (\(X_1\)) e informar o preço ideal para cada corrida (\(Y\)), esses seriam os dados populacionais.</p>
                    <p>Portanto, nosso problema consiste em encontrar o melhor estimador de \(\beta_1\), usando uma amostra aleatória dos dados populacionais do problema.</p>
                    <p>Além disso, o curso de Econometria I não visa te ensinar a criar um modelo de regressão simples do zero, nossa tarefa consiste apenas em avaliar a qualidade dos modelos sugerido pelos exercícios.</p>
                </section>

                <section id="teste-hipotese">
                    <h3>Teste de Hipótese</h3>
                    <p>Testes de hipótese ajudam a determinar se existem evidências suficientes para suportar uma determinada hipótese sobre a população com base nos dados amostrais. Essa hipótese normalmente é chamada de “hipótese alternativa” (\(H_1\)) e a hipótese consolidada sobre a população, ou melhor, o senso comum sobre a população, é chamado de “hipótese nula” (\(H_0\)).</p>
                    <p>No nosso caso, na P1, quase sempre a hipótese nula e alternativas serão:</p>
                    <p>
                        $$H_0:\beta_1 = 0$$
                        $$H_1:\beta_1 \neq 0$$
                    </p>
                    <p>A hipótese nula seria, nesse caso o coeficiente da variável explicativa (\(\beta_1\)) igual a zero. Ou seja, até que se rejeite essa hipótese nula, a variável explicativa selecionada não tem relação alguma com a variável dependente (\(Y\)).</p>
                    <p>Além disso, os teste de hipótese normalmente só são aplicados sobre os coeficientes das varivéis explicativas (\(\beta_{1,2,3,...}\)) (mesmo na P2). Via de regra, <b>não</b> vamos testar a significância estatística do intercepto (\(\beta_0\)).</p>
                    <p>Existem três formas de rejeitar a hipótese nula:</p>
                    <ul class="justified-list list-number">
                        <li>Usando Estatística-T e Valor Crítico;</li> <br>
                        <li>Usando P-valor e Nível de Significância;</li> <br>
                        <li>Usando Intervalo de Confiança (CI) e Hipótese Nula</li>
                    </ul>
                    <p>Vamos começar com a Estatística-T e Valor Crítico</p>

                    <h4>1. Estatística-T e Valor Critico (\(t^*\))</h4>
                    <p>Existem muitos “t”s em estatística, antes de começar a explicar a estatística-t gostaria de definir outros conceitos parecidos para que você não se confunda ao longo da leitura. “Estatística-T” ou “Estatística de Teste” <b>não</b> é a mesma coisa que “Distribuição T” ou “T-Student”. Preste atenção pois os dois conceitos serão usados neste teste de hipótese (1).</p>
                    
                    <ul class="justified-list">
                        <li><b>Valor Crítico (\(t^*\))</b></li>
                        <p>Distribuição-T também chamado de T-Student, é um tipo de distribuição parecida com a “normal” - também possui o formato de sino, porém com caldas mais largas (maior variabilidade). Ela é usada no lugar da normal quando a amostra é pequena e o desvio padrão da população é desconhecido (<b>pergunta de P1</b>) (a distribuição normal também é chamada de “distribuição-z”).</p>
                        <p>Assumindo que estamos falando de uma amostra que obedece a uma distribuição t, podemos usar a tabela a seguir (tabela-t) para achar o valor crítico. Via de regra, vamos usar a distribuição t sempre que quisermos calcular a significância estatística dos coeficientes <b>individualmente</b>.</p>
                        <p>Caso a estatística-t (conceito que vamos explicar a seguir) da amostra seja maior do que o valor crítico, podemos rejeitar a hipótese nula.</p>
                        <p>(imagem da tabela-t)</p>
                        <p>Contudo, para usar a tabela precisamos dos seguintes dados:</p>
                        <ul class="justified-list">
                            <li>graus de liberdade (\( gl \)) (eixo y na imagem)</li> <br>
                            <li>nível de significância (\( \alpha \)) e tipo de teste (uma calda ou duas caldas) (eixo x na imagem)</li>
                        </ul>
                        <p>Graus de liberdade (\(gl\)) são diretamente relacionados ao tamanho da amostra que você possui, quanto maior o tamanho da amostra (n) mais a distribuição t se assemelha a distribuição normal. Para calcular os graus de liberdade é muito simples, precisamos subtrair o tamanho da amostra (n) do experimento pelo número de coeficientes do modelo de regressão (k) (incluindo o intercepto - \(\beta_0\)).</p>
                        <p>
                            $$
                                gl=n-k
                            $$
                        </p>
                        <p>Onde:</p>
                        <p>gl = graus de liberdade (ou graus de liberdade dos resíduos)</p>
                        <p>n = número de observações da amostra</p>
                        <p>k = número de coeficientes/parâmetros do modelo (incluindo o intercepto)</p>
                        <p>Como estamos no modelo simples de regressão linear, “k” será sempre igual a 2. Logo, \(gl = n - 2\). Vale lembrar que, na maioria dos casos, o valor exato de \(gl\) não deve constar na tabela-t, nesse caso, você deve considerar o grau de liberdade mais próximo.</p>
                        <p>Quando estudarmos os "SQs" (ainda nessa seção - resumo da P1), vamos observar que existe um "cara" chamado <b>SQR</b>. Também podemos usar os graus de liberdade (\(gl\)) do SQR para descobrir o número de observações da amostra (\(n\)) - apenas do SQR. Por exemplo, SQR possui \(18gl\), logo: \(n = gl + k = 18 + 2 = 20\). Você <b>NÃO</b> deve utilizar os graus de liberdade da regressão (SQE) para encontrar o "n".</p>
                        <p>O próximo passo consiste em descobrir o eixo x da tabela-t, para isso precisamos descobrir o nível de significância (\( \alpha \)) do exercício, caso não seja informado, podemos considerar \( \alpha \) = 5% ou 0,05. Quando um pesquisador estabelece esse nível de significância, ele está dizendo que há uma chance de apenas 5% de rejeitar a hipótese nula quando ela é verdadeira (ou seja, quando o coeficiente populacional de fato é igual a zero).</p>
                        <p>Obs: Na primeira prova, também não precisamos nos preocupar com falsos positivos e falsos negativos (erro do tipo I e erro do tipo II, respectivamente), por isso vamos explica-los no Resumo P2.</p>
                        <p>Agora, só falta descobrir se estamos falando de um <b>teste de uma ou duas caldas</b>. Povão, isso é simples, se a hipótese alternativa for \(H_a:\beta_1<0\) ou \(H_a:\beta>0\) então esse é um teste <b>unicaudal</b>. Se a hipótese alternativa for \(H_a:\beta_1 \neq 0\) então esse teste é bicaudal. Quando estamos em um teste de duas caldas (maioria dos casos), precisamos dividir o nível de significância (\( \alpha \)) por dois (2) para encontrar o nível de significância na tabela-t. Logo, no nosso exemplo, vamos precisar dividir 0,05 por 2 (eixo x = 0,025).</p>
                        <p>Agora, basta traçar uma linha reta entre o \(gl\) e nível de significância (\( \alpha \)) na tabela-t para encontrar o valor crítico (\(t^*\)).</p>

                        <li><b>Estatística-T ou T-valor</b></li>
                        <p>Existem duas fórmulas para calcular a estatística t. Vamos precisar mostrar as duas fórmulas para entender a definição de estatística t:</p>
                        <p>
                            $$
                            t_{\beta_1}=\frac{\hat{\beta_1}-\beta_1}{SE}
                            $$
                            ou
                            $$
                            t_{\beta_1}=\frac{\hat{\beta_1}-\beta_1}{s}
                            $$
                        </p>
                        <p>Onde:</p>
                        <p>\(t\) = estatística t</p>
                        <p>\(\hat{\beta_1}\) = coeficiente amostral estimado (hipótese alternativa)</p>
                        <p>\(\beta_1\)= coeficiente populacional (hipótese nula)</p>
                        <p>\(SE\) = standard error (erro padrão)</p>
                        <p>\(s\) = desvio padrão amostral</p>
                        <p>Vamos abrir um parênteses aqui para explicar (1) erro padrão e (2) desvio padrão amostral:</p>
                        <p>(1) erro padrão (\(SE\)), nesse contexto, pode ser definido como a diferença de uma estatística - o coeficiente \(\hat{\beta_1}\), no nosso exemplo, de uma amostra para a outra de uma mesma população dado a aleatoriedade da variabilidade das amostras. Quanto maior o tamanho da amostra e menor a variabilidade entre as observações da amostra, portanto, menor o erro padrão. Segue a fórmula do erro padrão: \(SE = \frac{s}{\sqrt{n}}\)</p>
                        <p>(2) desvio padrão amostral (\(s\)), nesse contexto, pode ser definido como a medida de dispersão dos coeficientes estimados das diferentes amostras da mesma população. Ou seja, o desvio padrão é uma medida de “dispersão” e o erro padrão é uma medida de “precisão”.</p>
                        <p>Fechando parênteses.</p>
                        <p>Se estamos usando a primeira fórmula, a estatística-t estabelece quantos erros padrão (SE) o coeficiente amostral estimado (\(\hat{\beta_1}\)) se distância do coeficiente populacional (\(\beta_1\)), porém, no nosso teste de hipótese, \(\beta_1=0\) (hipótese nula). Logo, quanto maior a diferença entre o estimador do coeficiente amostral (\(\hat{\beta_1}\)) e a hipótese nula e quanto menor o erro padrão (SE), maior será a estatística t, o que indica que a chance desse resultado ser um fruto do mero acaso é menor.</p>
                        <p>Se estamos usando a segunda fórmula, a estatística-t estabelece quantos desvio padrão (s) o coeficiente amostral estimado (\(\hat{\beta_1}\)) se distância do coeficiente populacional (\(\beta_1\)), porém, no nosso teste de hipótese, \(\beta_1=0\) (hipótese nula). Logo, quanto maior a diferença entre o estimador do coeficiente amostral (\(\hat{\beta_1}\)) e a hipótese nula e quanto menor o desvio padrão (s), maior será a estatística t, o que indica que a chance desse resultado ser um fruto do mero acaso é menor.</p>
                        <p>Voltando para a definição de estatística t, ambos os casos são validos, porém com interpretações ligeiramente diferentes. Normalmente, vamos usar o primeiro o caso (SE).</p>
                        <p>Finalmente,</p>
                        <p>Com a estatística t e o valor crítico, basta validar se a estatística t em <b>termos absolutos</b> (ex: |-2,534| = 2,534) do coeficiente amostral é maior do que o valor crítico obtido na tabela, se for o caso, você pode rejeitar a hipótese nula.</p>
                        <p>Agora, vamos resolver o mesmo problema usando o p-valor e nível de significância.</p>
                    </ul>
                    
                    <h4>2. P-valor e Nível de Significância (\(\alpha\))</h4>
                    <p>P-valor representa uma probabilidade condicional (varia entre 0 a 1): dado que a hipótese nula é verdadeira, qual é a probabilidade do resultado amostral representar a população? Logo, se a hipótese nula for verdadeira, quanto menor o p-valor mais improvável será a observação do resultado da amostra. Um p-valor alto estaria confirmando a hipótese nula, em outras palavras, dado que a hipótese nula é verdade, esse resultado tem grande chance de ser observado na população. O p-valor ajuda pesquisadores a quantificar a força das suas evidências contra a hipótese nula. Se o p-valor for menor ou igual do que o nível de significância estabelecido pelo experimento (geralmente, 5%), podemos rejeitar a hipótese nula. Por exemplo, se o p-valor do estimador de um coeficiente (\(\hat{\beta_1}\)) for menor do que 0.0001 existe grande chance do seu coeficiente representar uma grande correlação com a variável explicativa - em outras palavras, rejeitar a hipótese nula (\(H_0:\beta_1=0\)).</p>
                    <p>Caso ainda precise de mais detalhes sobre o p-valor, assista o vídeo a seguir:</p>
                    <iframe width="100%" height="515" src="https://www.youtube.com/embed/z-HSsVARNnk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <br>
                    <ul class="justified-list">
                        <li>Como podemos usar a estatística-t para encontrar o p-valor usando a tabela-t (<b>pergunta de prova</b>)?</li>
                    </ul>
                    <p>Quando o p-valor não for fornecido, precisaremos encontrar o seu valor aproximado na tabela-t. Vamos considerar um exemplo com os seguintes dados:</p>
                    <p>\(gl = n - k = 30 - 2 = 28\)</p>
                    <p>estatística-t\((|t|) = \frac{\hat{\beta_1}-0}{SE(\hat{\beta_1})}=2,5\)</p>
                    <p>Passo-a-passo:</p>
                    <p>(imagem table-t)</p>
                    <ul class="justified-list list-number">
                        <li>Encontre a linha na tabela-t que corresponde aos graus de liberdade do exemplo (28);</li> <br>
                        <li>Nessa linha, encontre o(s) valor(es) crítico(s) mais próximo da estatística-t fornecida (2,5);</li> <br>
                        <li>Feito isso, basta observar o nível de significância dessa coluna;</li> <br>
                        <li>Agora, precisamos analisar o teste de hipótese, caso o teste de hipótese possua duas caldas, multiplique o valor encontrado no começo da coluna por 2, caso contrário, multiplique por 1. Esse é o valor aproximado do p-valor.</li>
                    </ul>
                    <p>Obs (passo 2): Caso a estatística-t seja muito alta, digamos 5, dificilmente a tabela-t conterá um valor crítico próximo a esse número dados os graus de liberdade (\(gl\)), portanto, você pode assumir que o p-valor é muito pequeno. Repare que os valores críticos a direita da coluna são maiores e estão associados a níveis de significância mais baixos.</p>

                    <h4>3. Intervalo de Confiança (CI) e Hipótese Nula (\(H_0\))</h4>
                    <p>O intervalo de confiança (CI) estabelece o intervalo em que a hipótese nula de \(\beta_1\) deve estar para que seja aceita, dado o nível de significância estabelecido (5%). Como no nosso exemplo a hipótese nula será sempre: \(H_0:{\beta_1}=0\), caso o intervalo de confiança (CI) não contenha 0 (zero), podemos rejeitar a hipótese nula.</p>
                    <p>CI pode ser calculado usando a seguinte fórmula:</p>
                    <p>
                        $$
                        CI = \hat{\beta_1}\pm t^* * SE(\hat{\beta_1})
                        $$
                    </p>
                    <p>\(\hat{\beta_1}\) = estimador do coeficiente de inclinação do modelo de regressão (hipótese alternativa)</p>
                    <p>\(t^*\) = valor crítico t obtido na tabela-t</p>
                    <p>\(SE(\hat{\beta_1})\) = erro padrão do estimador do coeficiente de inclinação do modelo de regressão</p>
                    <p>Vamos fazer um exemplo com os seguintes dados:</p>
                    <ul class="justified-list">
                        <li>Estimador do coeficiente angular (\(\hat{\beta_1}\)) = 2,5</li><br>
                        <li>Erro padrão do estimador do coeficiente angular (\(SE(\hat{\beta_1})\)) = 0,5</li><br>
                        <li>Tamanho da amostra (n) = 30</li><br>
                        <li>Número de variaveis explicativas (k) = 1</li>
                    </ul>
                    <p>Passo-a-passo:</p>
                    <ul class="justified-list list-number">
                        <li>Com isso, podemos calcular o valor crítico na tabela-t:</li>
                        <p>Para o nível de significância de 5% (como ele não foi informado, podemos assumir \(\alpha=5\%\)) e graus de liberdade \(gl = n - k = 30 - 2 = 28\), o valor crítico (\(t^*\)) na tabela-t seria de 2,048.</p>
                        <li>Agora, basta substituir na fórmula:</li>
                        <p>
                            $$
                                CI = \hat{\beta_1} \pm t^* * SE(\hat{\beta_1})
                            $$
                            $$
                                CI =2,5 \pm 2,048*0,5
                            $$
                            $$
                                CI = 2,5 \pm1,024
                            $$
                            $$
                                CI = (1,476;3,524)
                            $$
                        </p>
                    </ul>
                    <p>Interpretação:</p>
                    <ul class="justified-list">
                        <li>Para o nível de significância de 5%, o intervalo de confiança de \(\beta_1\) é (1,476 ; 3,524);</li><br>
                        <li>Como o intervalo não contém zero, podemos rejeitar a hipótese nula \(H_0:{\beta_1}=0\) ao nível de significância de 5%;</li><br>
                        <li>Isso indica que o \(\beta_1\) é significativamente diferente de zero, sugerindo que a relação entre a variável explicativa (\(X_1\)) associada a \(\beta_1\) e a variável dependente (\(Y\)) possui significância estatística.</li><br>
                    </ul>
                </section>

                <section id="qualidade-modelo">
                    <h3>Qualidade do Modelo de Regressão Simples</h3>
                    <p>Ta beleza, povão? (Se tiver achado alguma parte confusa, envie um <a href="#introducao">e-mail</a> para gente)</p>
                    <p>Nesta seção vamos explicar como podemos avaliar a qualidade do modelo de regressão. Preste atenção pois essa matéria também faz parte daqueles “70%” da P1.</p>
                    <p>Vamos começar explicando o coeficiente de determinação (\(R^2\)):</p>

                    <h4>Coeficiente de Determinação (\(R^2\))</h4>
                    <p>O coeficiente de determinação mensura quão bem a variável independente (X) explica a variação na variável dependente (Y), dentro de uma determinada <b>amostra</b> (esse detalhe é importante para entender a estatística F). Essa estatística indica a proporção da variação na variável dependente (Y) que é explicada pela variável explicativa (X). Seu valor varia entre 0 e 1. 0 indica que a variável explicativa (X) não explica a variação na variável dependente (Y), e 1.</p>
                    <p>O \(R^2\) é medido dentro do contexto da amostra, ou seja, amostras diferentes da mesma população podem resultar em coeficientes de determinação diferentes, mas servem como estimadores do \(R^2\) populacional. Quanto maior o R ao quadrado, mais o modelo de regressão simples consegue explicar o que acontece com a variável dependente dentro da população.</p>
                    <p>Nesse caso, como estamos falando de um modelo de regressão simples - com uma unica variável explicativa, o coeficiente de determinação (\(R^2\)) servirá bem esse propósito. Por sua vez, existem uma situção em que o coeficiente de determinação não é recomendado:</p>
                    <p>Quando queremos comparar a qualidade de dois modelos de regressão com quantidades diferentes de variaveis explicativas (X), como por exemplo, um modelo de regressão simples e um modelo de regressão múltiplo.</p>
                    <p>Isso acontece pois sempre que aumentamos o número de variaveis explicativas (k), o \(R^2\) será positivamente impactado, mesmo que as variaveis explicativas (X) adicionadas não ajudem a explicar a variação da variável dependente (Y).</p>
                    <p>Obs: Na P1, não precisamos “ajustar” o coeficiente de determinação. Vamos “ajustar” o R ao quadrado pela “quantidade de variaveis explicativas” (ou k) na seção de Resumo P2.</p>
                    <p>Segue a fórmula de calculo do \(R^2\):</p>
                    <p>
                        $$
                            R^2=1-\frac{SQR}{SQT}
                        $$
                        ou
                        $$
                            R^2=\frac{SQE}{SQT}
                        $$
                    </p>
                    <p>Onde:</p>
                    <p>\(R^2\) = coeficiente de determinação;</p>
                    <p>\(SQT\) = soma total dos quadrados da variável dependente (y) (SST em inglês) - soma da diferença entre o valor observado de y e a sua média amostral \(\bar{y}\) ao quadrado;</p>
                    <p>\(SQE\) = soma dos quadrados <b>explicados</b> pelo modelo de regressão (SSR em inglês) - soma da diferença entre o valor estimado pelo modelo de regressão \(\hat{y}\) para aquela observação e a média amostral \(\bar{y}\) ao quadrado;</p>
                    <p>\(SQR\) = soma dos quadrados dos <b>resíduos</b> da variável dependente (y) ou soma dos quadrados dos erros (SSE em inglês) - soma da diferença entre o valor observado de y e o valor estimado pelo modelo \(\hat{y}\) ao quadrado.</p>
                    <p>A fórmula é simples, porém, o que essa razão representa na prática?</p>
                    <p>O SQR representa a variabilidade de Y que não pode ser explicada pelas variáveis explicativas do modelo - o residual (u), portanto, quanto maior o SQR relativamente ao SQT, maior será a proporção da variação da variável dependente (Y) que <b>não</b> pode ser explicada pelo modelo de regressão. Essa razão “menos 1” fornece quanto a variabilidade total da variável dependente (Y) é explicada pelas variaveis explicativas do modelo.</p>
                    <p>Vamos aproveitar para entender os conceitos adjacentes a \(R^2\), os “SQs”.</p>

                    <h4>Decomposição da Soma Total dos Quadrados (”SQs”)</h4>
                    <p>No contexto do modelo de regressão, os “SQs” são um conjunto de estatísticas que ajudam a medir a efetividade do modelo de regressão. Sempre serão calculados com base nas observações das variaveis dependentes (\(y\)) da amostra.</p>
            
                    <p>A fórmula do Coeficiente de Determinação (\(R^2\)) está intimamente ligada ao SQT, portanto, os dois possuem interpretações parecidas. Porém, diferente do \(R^2\) que está preocupado em explicar a proporção da variável dependente que é explicada pelo modelo de regressão, o SQT está preocupado em determinar a variação total da variável dependente (y) que precisa ser explicada pelo modelo de regressão. Como você pode ver na fórmula abaixo, o SQT pode ser calculado pela soma de SQE e SQR, onde SQE representa a variação que pode ser explicada pelo modelo de regressão e SQR representa a parte que não pode ser explicada pelo modelo - o residual (u).</p>
                    <p>
                        $$
                            SQT=SQE+SQR
                        $$
                    </p>
                    <ul class="justified-list">
                        <li>Soma Total dos Quadrados (SQT)</li>
                        <p>Se por acaso for necessário calcular o SQT usando as observações da amostra (isso não costuma acontecer), sem usar a fórmula acima, ela pode ser calculado pela soma da diferença das variaveis dependentes (\(y\)) em relação a sua média (\(\bar{y}\)) elevado ao quadrado:</p>
                        <p>
                            $$
                                SQT = \sum^n_{i=1}(y_i-\bar{y})^2
                            $$
                        </p>
                        <p>Logo, quanto maior o SQT, maior a variabilidade da amostra em relação a média. Portanto, o SQT pode variar de 0 (zero) a mais infinito. </p>
                        <p>Imagine um “gráfico de bolinhas” (scatter chart) com as variaveis dependentes (\(y\)), agora desenhe uma linha horizontal que representa a média das variaveis dependentes da amostra (\(\bar{y}\)). A distância de cada observação para essa linha horizontal representa a variação total dos dados (SQT).</p>

                        <li>Soma dos Quadrados Explicada pela Regressão (SQE)</li>
                        <p>Quantifica quanto da variação total de \(y\) é capturada pelo modelo de regressão.</p>
                        <p>
                            $$
                                SQE=\sum^n_{i=1}(\hat{y}_i - \bar{y})^2
                            $$
                        </p>
                        <p>Um SQE maior relativo ao SQT sugere um modelo mais ajustado. Talvez você não tenha entendido o valor de \(\hat{y}_i\), mas ele é calculado para cada linha da sua tabela (amostra) usando o valor de \(x_1\) e o modelo de regressão criado: \(\hat{y}_i=\beta_0+\beta_1x_i\).</p>
                        <p>A distância de cada ponto de dados da linha do modelo de regressão representa a variação que não é explicada pelo modelo - o residual (SQR).</p>

                        <li>Soma dos Quadrados dos Resíduos (SQR)</li>
                        <p>Quantifica a variabilidade total de \(y\) que não é explicada pelo modelo de regressão.</p>
                        <p>
                            $$
                                SQR=\sum^n_{i=1}(y_i-\hat{y}_i)^2
                            $$
                        </p>
                        <p>Um SQR maior sugere um encaixe <b>menor</b> do modelo de regressão com os dados da amostra. Repare que, ao <b>não</b> rejeitar a hipótese nula: \(SQT = SQR\) (importante na P2).</p>
                        <p>A distância da linha de regressão e a linha de média representa a variação que é explicada pelo modelo (SQE).</p>
                    </ul>
                </section>
            </section>
            <section id="resumoP2">

                <section id="intro-p2">
                    <h2>Resumo P2</h2>
                    <p>As análises feitas na primeira parte do curso continuam verdadeiras, a não ser por algumas relações que se restringem ao caso específico da regressão simples com uma variável explicativa. Primeiramente, vamos lembrar de como normalmente testamos a significância estatística de uma variável explicativa de um modelo bastante simples (como fizemos na primeira parte do curso), para, em seguida, partimos para o caso de múltiplas variáveis explicativas.</p>
                </section>
                
                <section id="regressao-multipla">
                    <h3>Modelo de Regressaão Múltipla</h3>
                    <p>Considere a regressão: </p>
                    <p>
                        $$
                            Y_t = \beta_0 + \beta_1X_t + u_t
                        $$
                    </p>
                    <p>Caso seja do nosso interesse testar a significância estatística de Xt, aplicamos o seguinte teste:</p>
                    <p>
                        $$
                            H_0: \beta_1 = 0
                        $$
                        $$
                            H_1: \beta_1 \neq 0
                        $$
                    </p>
                    <p>Para melhor compreensão do teste de hipótese (seja para o caso de uma variável ou múltiplas), é útil entendermos que o teste acima possui uma outra formulação:</p>
                    <p>
                        $$
                            H_0: Y_t = \beta_0 + u_t 
                        $$
                        <span>Modelo Restrito (MR)</span>
                        $$
                            H_1: Y_t = \beta_0 + \beta_1X_t + u_t 
                        $$
                        <span>Modelo Irrestrito (MI)</span>
                    </p>
                    <p>A nossa interpretação continua sendo a mesma, caso aceitemos a hipótese nula, estaríamos concluindo que há evidencias estatísticas para que \(X_t\) seja não significativo, ou seja, de pouco interesse para explicar \(Y_t\), por isso excluímos o parâmetro \(\beta_1\) da regressão. Evidentemente, caso rejeitemos a hipótese nula, há evidencias estatísticas para dizermos que \(X_t\) é estatisticamente significativo, ou seja, útil em alguma medida para explicar \(Y_t\).</p>
                </section>
                
                <section id="mr-mi">
                    <h3>Modelo Restrito (MR) e Irrestrito (MI)</h3>
                    <p>O conceito de modelo restrito e irrestrito certamente é simples, mas é indispensável quando estamos testando hipóteses sobre uma regressão com múltiplas variáveis explicativas. Além de simples, o conceito é intuitivo. Visualmente, no teste de hipótese logo acima, podemos ver que o modelo restrito é mais enxuto do que o modelo irrestrito, isso ocorre exatamente pelo fato de ser uma versão reduzida do modelo com todas as variáveis explicativas possíveis, por definição, o modelo restrito irá aplicar todas as restrições que estão sendo testadas no teste de hipóteses ao modelo. Já o irrestrito, será igual ao modelo “original”, sem aplicar nenhuma restrição. Segue mais um exemplo abaixo:</p>
                    <p>
                        Modelo:
                        $$
                            Y_t = \beta_0 + \beta_1X_{t1} + \beta_2X_{t2} + \beta_3X_{t3} + \beta_4X_{t4} + u_t
                        $$
                    </p>
                    <p>
                        Teste de hipótese,
                        $$
                            H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = 0
                        $$
                        $$
                            H_1: Algum \beta \neq 0
                        $$
                        Ou,
                        $$
                            H_0: Y_t = \beta_0 + u_t
                        $$
                        <span>Modelo Restrito (MR)</span>
                        $$
                            H_1: Y_t = \beta_0 + \beta_1X_{t1} + \beta_2X_{t2} + \beta_3X_{t3} + \beta_4X_{t4} + u_t
                        $$
                        <span>Modelo Irrestrito (MI)</span>
                    </p>
                    <p>Vale ressaltar o impacto de modelo restrito e irrestrito nos "SQs". O valor de SQT não muda entre o modelo restriro e irrestrito, dado que SQT representa a variação de \(Y\) que precisa ser explicada pelo modelo de regressão. Porém, no modelo restrito, ou seja, quando a hipótese nula <b>não</b> é rejeitada, toda a variação de \(Y\) deve ser explicada pela soma dos quadrados dos resíduos (SQR). Logo, \(SQT = SQR\).</p>
                </section>
                
                <section id="estatistica-f">
                    <h3>Teste F</h3>
                    <p>Inicialmente, uma pergunta que pode surgir é: qual é a utilidade de migrarmos da estatística t para a F? A resposta está no objetivo que o pesquisador tem quando está testando uma hipótese, caso o interesse seja apenas descobrir se uma variável é estatisticamente significativa, basta usarmos o conhecimento que temos até o momento (estatística t), entretanto, se for do interesse descobrir se um conjunto de variáveis explicativas são significativas, precisamos recorrer a um outro ferramentário estatístico (F). Até o momento o cálculo da estatística F tem sido feito somente pela relação existente com a estatística t. Como sabemos que a primeira é, por definição, a razão de duas distribuições qui-quadrado, conseguimos inferir que t2 = F (isso serve apenas quando há uma restrição na hipótese nula!). Segue breve revisão abaixo.</p>
                    <p>Considerando X ~ N(0,1)  e X2 ~ X2n (qui-quadrado com n graus de liberdade), e que X e Y são independentes, é possível dizer que:</p>
                    <p>
                        $$
                            t^2 = (\frac{X_1}{\square\frac{X_2}{n}})^2 = \frac{X_1^2}{\frac{X_2}{n}} = \frac{\frac{X_1^2}{1}}{\frac{X_2}{n}} ~ F_{1,n}
                        $$
                    </p>
                    <p>Entretanto essa forma de se chegar à estatística F é bastante restrita, sendo útil apenas para um caso específico. Nessa seção iremos mostrar mais duas formas mais gerais de se chegar à estatística F.</p>
                    <ul class="justified-list">
                        <li>Primeira forma:</li>
                        $$
                            F = \frac{\frac{(SQR_{MR}-SQR_{MI})}{k-p}}{\frac{SQR_{MI}}{n-k}}
                        $$
                        <li>Segunda forma:</li>
                        $$
                            F = \frac{\frac{(R^2_{MI}-R^2_{MR})}{k-p}}{\frac{(1-R^2_{MI})}{n-k}}
                        $$
                    </ul>
                    <p>Onde:</p>
                    <p>\(k-p\) ou \(q\) = número de coeficientes na hipótese nula (sem considerar o intercepto). Também chamado de "número de restrições".</p>
                    <p>\(n-k\) = graus de liberdade do modelo irrestrito - \(gl_{irrestrito}\)</p>
                    <p>\(SQR_{MR}\) = no caso do modelo restrito: \(SQR_{MR} = SQT\) - sem rejeitar a hipótese nula, toda a variação de \(Y\) é explicada pelo termo de erro ou residual.</p>
                    <p>\(SQR_{MI}\) = no caso do modelo irrestrito: \(SQR_{MI} = SQT - SQE_{MI}\)</p>
                    <p>Com as duas fórmulas acima conseguimos calcular a estatística F, processo que ficará mais claro na seção de exemplos práticos. Por fim é importante ressaltar como funciona o processo de aceitação ou rejeição de hipóteses com a F.</p>
                    <p>Como já foi dito nos parágrafos acima, a estatística F vai ser utilizada na realização de testes sobre a significância conjunta das variáveis explicativas, ou seja, sobre o quão relevantes algumas variáveis de fato são para o modelo. O método de se fazer isso, essencialmente, não é diferente do que já estamos acostumados. Vamos precisar de algumas coisas: 1. A distribuição F, 2. Nível de significância, 3. Nossa estatística F. Simples!</p>
                    <img src="\static\img\distribuicao-f.png" alt="gráfico da distribuicao-f" style="width: 100%;">
                    <p>A estatística F, diferente da t e normal, possui apenas valores positivos (ver gráfico acima), tendo em vista que, por definição, é a razão de duas qui-quadrado. Dessa forma não é necessário dividir o alpha (grau de significância) por 2, podemos concentrar tudo num lado só.</p>
                    <p>Por último, a F possui 2 graus de Liberdade (Fgrau 1, grau 2), o resulta em uma tabela inédita. Teremos tabelas diferentes para cada grau de significância (1%,2,5%,5%,10%...), assim sendo possível incluirmos na tabela os dois graus de liberdade (um na linha e outro na coluna). Segue exemplo abaixo,</p>
                    <img src="\static\img\tabela-f.jpg" alt="tabela-f" style="width: 100%;">
                    <br>
                </section>
                
                <section id="r2-ajustado">
                    <br>
                    <h3>R2 Ajustado</h3>
                    <p>Como vimos na primeira parte do curso, o \(R^2\) possui um problema intrínseco. Quanto maior o número de variaveis explicativas, maior será o \(R^2\) - mesmo que essas variáveis não ajudem a explicar a variavel dependente (\(Y\)). Isso incentiva o pesquisador a inserir cada vez mais variáveis explicativas no modelo de regressão, tendo em vista que esse acréscimo de variáveis beneficia o \(R^2\) - na medida em que também aumenta o SQE.</p>
                    <p>Para resolver esse problema existe o <b>\(R^2\) ajustado (\(\bar{R^2}\))</b>, iremos brevemente destacar algumas de suas características. Observe a fórmula a seguir:</p>
                    <p>
                        $$
                            \bar{R^2} = 1 - (1 - R^2)\frac{n-1}{n-k}
                        $$
                    </p>
                    <ul class="justified-list list-number">
                        <li>Considerando que k é o número de parâmetros na regressão (considerando o intercepto) e n é o número de observações na amostra, podemos dizer que quando k > 1, \(\bar{R^2} \lt R^2\).</li> <br>
                        <li>É possível termos \(\bar{R^2}\) <b>negativo</b>! Basta tudo que está a direita do primeiro “1” ser maior que 1, para isso acontecer: \(R^2\) = 0 ou \(k \gt n\). No último caso, estamos dizendo que o número de coeficientes do modelo de regressão é maior do que o tamanho da amostra.</li> <br>
                        <li>\(\bar{R^2}\) ajustado pode ser igual ao \(R^2\) padrão, basta que \(R^2 = 1\).</li><br>
                    </ul>
                </section>
                
                <section id="dummys">
                    <h3>Variáveis Dummy</h3>
                    <p>Considere a regressão abaixo:</p>
                    <p>
                        $$
                            Y_t = \beta_0 + \beta_1D_{1t} + \beta_2D_{2t} + \beta_3X_t
                        $$
                    </p>
                    <p>Onde:</p>
                    <p>\(Y_t\):  Nota dos estudantes de econometria.</p>
                    <p>\(D_{1t}\): Variável binária que assume valor 1 caso o estudante faça a prova em menos de uma hora e 0 caso o contrário.</p>
                    <p>\(D_{2t}\): Variável binária que assume valor 1 caso o estudante faça a prova de lápis e 0 caso contrário.</p>
                    <p>\(X_t\): Número de horas estudadas.</p>
                    <p> Note que as variáveis dummy são essas que assumem apenas dois valores, elas buscam captar possíveis diferenças entre grupos amostrais distintos. </p>
                    <p>Digamos que a regressão acima, ao ser estimada, tenha o seguinte resultado:</p>
                    <p>
                        $$
                            Y_t = 0,5 - 3D_{1t} + 1D_{2t} + 0,5X_t
                        $$
                    </p>
                    <p>O que podemos dizer a partir do resultado acima?</p>
                    <p>É valido interpretar, primeiramente, o cenário “base”, em que as dummys assumem o valor 0. Nesse caso, estaríamos olhando para aquele estudante que termina a prova em mais de 1 hora e faz a prova de caneta. Nesse caso ficaríamos apenas com o intercepto e o coeficiente angular (0,5 + 0,5X).</p>
                    <p>Está claro que quanto mais horas estudadas, maior tende a ser a nota do aluno, agora vamos analisar o impacto das dummys (a primeira vista).</p>
                    <p>\(D_{1t}\): Pode-se dizer, considerando o sinal negativo (-3) e sem olhar a significância estatística da estimação, que alunos que terminam a prova em menos de uma hora tendem a ter notas menores.</p>
                    <p>\(D_{2t}\): Pode-se dizer, considerando o sinal positivo e sem olhar a significância estatística da estimação, que alunos que não utilizam lápis tendem a ter resultados melhores na prova (são mais confiantes talvez?).</p>
                    <p>Essa análise seria uma primeira etapa, agora para concluir vamos olhar para a significância estatística dos parâmetros estimados para as variáveis binárias (nível de significância de 5%).</p>
                        <table>
                            <thead><tr><th>Parâmetro</th>	<th>P-Valor</th></tr></thead>
                            <tbody>
                                <tr><td>B1</td>	<td><0,001</td></tr>
                                <tr><td>B2</td>	<td>0,2</td></tr>
                            </tbody>
                        </table>
                    <p>Apesar do que foi dito acima, quando olhamos para a significância estatística concluímos que há evidencias estatísticas, ao nível de 5% de significância, para se dizer que não há diferença relevante entre os alunos que utilizam lápis ou caneta para fazer a prova.</p>
                </section>
            </section>
        </main>
        <aside class="side-menu right">
            <h2>Important Notes & News</h2>
            <!-- Notes and news content here -->
        </aside>
    </div>
    <footer>
        <p>&copy; 2024 Professor Diogo Braga</p>
    </footer>
    <script src="..\static\script.js"></script>
</body>
</html>
