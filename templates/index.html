<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Econometria I</title>
    <link rel="stylesheet" href="..\static\styles.css">
    <!-- icones -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <!-- formulas e equações -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <header>
        <h1>Econometria I</h1>
    </header>
    <div class="container">
        <nav class="side-menu left">
            <ul>
                <li class="menu-item">
                    <a href="#resumoP1">Resumo P1</a>
                    <ul class="submenu">
                        <li><a href="#regressao-simples">Regressão Simples</a></li>
                        <li><a href="#teste-hipotese">Teste de Hipótese</a></li>
                        <li><a href="#qualidade-modelo">Qualidade do Modelo</a></li>
                    </ul>
                </li>
                <li class="menu-item">
                    <a href="#resumoP2">Resumo P2</a>
                </li>
                <li class="menu-item">
                    <a href="#">Provas</a>
                    <ul class="submenu">
                        <li><a href="#">P1 2023.2</a></li>
                        <li><a href="#">P2 2023.2</a></li>
                        <li><a href="#">P1 2023.1</a></li>
                        <li><a href="#">P2 2023.1</a></li>
                        <li><a href="#">P1 2022.2</a></li>
                        <li><a href="#">P2 2022.2</a></li>
                    </ul>
                </li>
                <li class="menu-item">
                    <a href="">Listas</a>
                </li>
            </ul>
        </nav>
        <main>
            <section id="introducao">
                <h2>Povão,</h2>
                <p>O objetivo desse site é nivelar o conhecimento necessário para passar no curso de Econometria I <b>noturno</b> de Ciências Econômicas na UFF. Em alguns momentos, propositalmente, vamos preferir usar uma linguagem mais simples ao invés do jargão estatístico para facilitar a compreensão. Além disso, vamos relembrar alguns conceitos que você talvez não se lembre de estatística I e II.</p>
                <p>Se você está procurando pelo conteúdo do curso da manhã ou deseja fornecer um feedback, envie um e-mail para <a href="mailto:jggmartins@id.uff.br;joaostrauss@id.uff.br?subject=Site%20de%20Econometria%20I">jggmartins@id.uff.br</a> (João Gabriel - desenvolvedor do site) ou <a href="mailto:joaostrauss@id.uff.br;jggmartins@id.uff.br?subject=Site%20de%20Econometria%20I">joaostrauss@id.uff.br</a> (João Strauss - monitor do curso de econometria I).</p>
            </section>
            <section id="resumoP1">

                <section id="intro">
                    <h2>Resumo P1</h2>
                    <p>Na primeira parte do curso (até a P1), vamos nos restringir a um modelo de regressão com dois coeficientes (\(\beta_0\) e \(\beta_1\)) e uma variável explicativa (\(X_1\)) - modelo de regressão simples. Eu diria que 70% da P1 consiste em conseguir resolver esse problema, não sugiro que você ignore os outros 30%, mas nessa seção vamos tratar de explicar o principal problema da P1.</p>
                </section>

                <section id="regressao-simples">
                    <h3>Modelo Simples de Regressão Linear</h3>
                    <p>$$ Y = \beta_0 + \beta_1X_1 + u $$</p>
                    <p>\(Y\) = Variável dependente</p>
                    <p>\(\beta_0\) = Coeficiente do intercepto</p>
                    <p>\(\beta_1\) = Coeficiente da variável explicativa</p>
                    <p>\(X_1\) = Variável explicativa ou variável independente</p>
                    <p>\(u\) = residual/termo de erro</p>
                    <p>O exercício consiste em encontrar a melhor variável explicativa para a variável dependente (\(Y\)). Quanto maior a correlação entre as duas variáveis, maior será o valor de \(\beta_1\), ou seja, \(\beta_1\) representa o impacto que uma alteração unitária em \(X_1\) pode causar em \(Y\). Logo, quanto maior \(\beta_1\), maior será a parcela de Y que será explicada pela variável explicativa (\(X_1\)). Por sua vez, o “termo de erro” ou “residual” (\(u\)) serve para representar todo o restante que não pode ser explicado pela variável explicativa e coeficiente de intercepto usados no modelo.</p>
                    <p>Porém, nunca conseguimos ter 100% de certeza de que aquele coeficiente (\(\beta_1\)) (por exemplo: 0,81) de fato impacta a variável explicativa (\(Y\)) na magnitude informada, isso porque no mundo real raramente teremos acesso aos dados populacionais, apenas a uma amostra desses dados. Por exemplo, digamos que a variável dependente (\(Y\)) seja o preço da corrida na Uber, e vamos considerar que \(X_1\) seja a distância entre o ponto de partida e o ponto de chegada em Kms. Logo, seria impossível montar um banco de dados com todas as distâncias entre dois pontos do planeta (\(X_1\)) e informar o preço ideal para cada corrida (\(Y\)), esses seriam os dados populacionais.</p>
                    <p>Portanto, nosso problema consiste em encontrar o melhor estimador de \(\beta_1\), usando uma amostra aleatória dos dados populacionais do problema.</p>
                    <p>Além disso, o curso de Econometria I não visa te ensinar a criar um modelo de regressão simples do zero, nossa tarefa será apenas avaliar a qualidade dos modelos sugeridos pelos exercícios.</p>
                </section>

                <section id="teste-hipotese">
                    <h3>Teste de Hipótese</h3>
                    <p>Testes de hipótese ajudam a determinar se existem evidências suficientes para suportar uma determinada hipótese sobre a população com base nos dados amostrais. Essa hipótese normalmente é chamada de “hipótese alternativa” (\(H_1\)) e a hipótese consolidada sobre a população, ou melhor, o senso comum sobre a população, é chamado de “hipótese nula” (\(H_0\)).</p>
                    <p>No nosso caso, na P1, quase sempre a hipótese nula e alternativas serão:</p>
                    <p>
                        $$H_0:\beta_1 = 0$$
                        $$H_1:\beta_1 \neq 0$$
                    </p>
                    <p>A hipótese nula (senso comum) que pode ser rejeitada, seria, nesse caso: coeficiente da variável explicativa \(\beta_1\) igual a zero. Ou seja, até que se rejeite essa hipótese, a variável explicativa selecionada não tem relação alguma com a variável dependente (Y).</p>
                    <p>Existem duas formas de rejeitar a hipótese nula:</p>
                    <ul class="justified-list list-number">
                        <li>Usando Estatística-T e Valor Crítico;</li>
                        <li>Usando P-valor e Nível de Significância;</li>
                        <li>Usando Intervalo de Confiança (CI) e Valor Crítico</li>
                    </ul>
                    <p>Vamos começar com a Estatística-T e Valor Crítico</p>

                    <h4>1. Estatística-T e Valor Critico (\(t^*\))</h4>
                    <p>Existem muitos “t”s em estatística, antes de começar a explicar a estatística-t gostaria de definir outros conceitos parecidos para que você não se confunda ao longo da leitura. “Estatística-T” ou “Estatística de Teste” <b>>não</b> é a mesma coisa que “Distribuição T” ou “T-Student”. Preste atenção pois os dois conceitos serão usados neste teste de hipótese (1).</p>
                    
                    <h5>Valor Crítico</h5>
                    <p>Distribuição-T também chamado de T-Student, é um tipo de distribuição parecida com a “normal” - também possui o formato de sino, porém com caldas mais largas (maior variabilidade). Ela é usada no lugar da normal quando a amostra é pequena e o desvio padrão da população é desconhecido (<b>pergunta de P1</b>) (a distribuição normal também é chamada de “distribuição-z”).</p>
                    <p>Assumindo que estamos falando de uma amostra que obedece a uma distribuição t, podemos usar a tabela a seguir (tabela-t) para achar o valor crítico. Via de regra, vamos usar a distribuição t sempre que quisermos calcular a significância estatística dos coeficientes <b>individualmente</b>.</p>
                    <p><u>Caso a estatística-t (conceito que vamos explicar a seguir) da amostra seja maior do que o valor crítico, podemos rejeitar a hipótese nula.</u></p>
                    <p>(imagem da tabela-t)</p>
                    <p>Contudo, para usar a tabela precisamos dos seguintes dados:</p>
                    <ul class="justified-list">
                        <li>graus de liberdade (\( df \)) (eixo y na imagem)</li>
                        <li>nível de significância (\( \alpha \)) e tipo de teste (uma calda ou duas caldas) (eixo x na imagem)</li>
                    </ul>
                    <p>Graus de liberdade (\(df\)) são diretamente relacionados ao tamanho da amostra que você possui, quanto maior o tamanho da amostra (n) mais a distribuição t se assemelha a distribuição normal. Para calcular os graus de liberdade é muito simples, precisamos subtrair o tamanho da amostra (n) do experimento pelo número de variaveis explicativas do modelo de regressão (k) menos 1 (um).</p>
                    <p>
                        $$
                        df=n-k-1
                        $$
                    </p>
                    <p>Como estamos no modelo simples de regressão linear, “k” será sempre igual a 1. Logo, \(df = n - 2\). Vale lembrar que, novamente, na maioria dos casos, o valor exato de \(df\) não deve constar na tabela-t, nesse caso, você deve considerar o grau de liberdade mais próximo.</p>
                    <p>O próximo passo consiste em descobrir o eixo x da tabela-t, para isso precisamos descobrir o nível de significância (\( \alpha \)), que normalmente é fornecido pelo exercício e, caso não seja informado, podemos considerar \( \alpha \) = 5% ou 0,05. Quando um pesquisador estabelece esse nível de significância, ele está dizendo que há uma chance de 5% de rejeitar a hipótese nula quando ela é verdadeira (ou seja, quando o coeficiente populacional de fato é igual a zero).</p>
                    <p>Obs: Na primeira prova, também não precisamos nos preocupar com falsos positivos e falsos negativos (erro do tipo I e erro do tipo II, respectivamente), por isso vamos explica-los no Resumo P2.</p>
                    <p>Agora, só falta descobrir se estamos falando de um <b>teste de uma ou duas caldas</b>. Povão, isso é simples, se a hipótese alternativa for \(H_a:\beta_1<0\) ou \(H_a:\beta>0\) então esse é um teste <b>unicaudal</b>. Se a hipótese alternativa for \(H_a:\beta_1 \neq 0\) então esse teste é bicaudal. Quando estamos em um teste de duas caldas (maioria dos casos), precisamos dividir o nível de significância (\( \alpha \)) por dois (2) para encontrar o nível de significância na tabela-t. Logo, no nosso exemplo, vamos precisar dividir 0,05 por 2 (0,025).</p>
                    <p>Agora basta traçar uma linha reta entre o \(df\) e nível de significância (\( \alpha \)) na tabela-t para encontrar o valor crítico.</p>
                    
                    <h5>Estatística-T ou T-valor</h5>
                    <p>Existem duas fórmulas para calcular a estatística t. Vamos precisar mostrar as duas fórmulas para entender a definição de estatística t:</p>
                    <p>
                        $$
                        t_{\beta_1}=\frac{\hat{\beta_1}-\beta_1}{SE}
                        $$
                        ou
                        $$
                        t_{\beta_1}=\frac{\hat{\beta_1}-\beta_1}{s}
                        $$
                    </p>
                    <p>\(t\) = estatística t</p>
                    <p>\(\hat{\beta_1}\) = coeficiente amostral (hipótese alternativa)</p>
                    <p>\(\beta_1\)= coeficiente populacional (hipótese nula)</p>
                    <p>\(SE\) = standard error (erro padrão)</p>
                    <p>\(s\) = desvio padrão amostral</p>
                    <p>Vamos abrir um parênteses aqui para explicar:</p>
                    <p>(1) erro padrão (\(SE\)), nesse contexto, pode ser definido como a diferença de uma estatística - o coeficiente \(\hat{\beta_1}\), no nosso exemplo, de uma amostra para a outra de uma mesma população dado a aleatoriedade da variabilidade das amostras. Quanto maior o tamanho da amostra e menor a variabilidade entre as observações da amostra, portanto, menor o erro padrão. Segue a fórmula do erro padrão: \(SE = \frac{s}{\sqrt{n}}\)</p>
                    <p>(2) desvio padrão amostral (\(s\)), nesse contexto, pode ser definido como a medida de dispersão dos coeficientes estimados das diferentes amostras da mesma população. Ou seja, o desvio padrão é uma medida de “dispersão” e o erro padrão é uma medida de “precisão”.</p>
                    <p>Fechando parênteses.</p>
                    <p>Se estamos usando a primeira fórmula, essa estatística estabelece quantos erros padrão (SE) o coeficiente amostral estimado (\(\hat{\beta_1}\)) se distância do coeficiente populacional (\(\beta_1\)), porém, no nosso teste de hipótese, \(\beta_1=0\) (hipótese nula). Logo, quanto maior a diferença entre o estimador do coeficiente amostral (\(\hat{\beta_1}\)) e a hipótese nula e quanto menor o erro padrão (SE), maior será a estatística t, o que indica que a chance desse resultado ser um fruto do mero acaso é menor.</p>
                    <p>Se estamos usando a segunda fórmula, essa estatística estabelece quantos desvio padrão (s) o coeficiente amostral estimado (\(\hat{\beta_1}\)) se distância do coeficiente populacional (\(\beta_1\)), porém, no nosso teste de hipótese, \(\beta_1=0\) (hipótese nula). Logo, quanto maior a diferença entre o estimador do coeficiente amostral (\(\hat{\beta_1}\)) e a hipótese nula e quanto menor o desvio padrão (s), maior será a estatística t, o que indica que a chance desse resultado ser um fruto do mero acaso é menor.</p>
                    <p>Voltando para a definição de estatística t, ambos os casos são validos, porém com interpretações ligeiramente diferentes. Normalmente, vamos usar o primeiro o caso (SE).</p>
                    <p>Finalmente,</p>
                    <p>Com a estatística t e o valor crítico, basta validar se a estatística t em <b>termos absolutos</b> (ex: |-2,534| = 2,534) do coeficiente amostral é maior do que o valor crítico obtido na tabela, se for o caso, você pode rejeitar a hipótese nula.</p>
                    <p>Agora, vamos resolver o mesmo problema usando o p-valor e intervalo de confiança.</p>

                    <h4>2. P-valor e Nível de Significância (\(\alpha\))</h4>
                    <p>P-valor representa uma probabilidade condicional (varia entre 0 a 1): dado que a hipótese nula é verdadeira, qual é a probabilidade do resultado amostral representar a população? Logo, se a hipótese nula for verdadeira, quanto menor o p-valor mais improvável será a observação do resultado da amostra. Um p-valor alto estaria confirmando a hipótese nula, em outras palavras, dado que a hipótese nula é verdade, esse resultado tem grande chance de ser observado na população. O p-valor ajuda pesquisadores a quantificar a força das suas evidências contra a hipótese nula. Se o p-valor for menor ou igual do que o nível de significância estabelecido pelo experimento (geralmente, 5%), podemos rejeitar a hipótese nula. Por exemplo, se o p-valor do estimador de um coeficiente (\(\hat{\beta_1}\)) for menor do que 0.0001 existe grande chance do seu coeficiente representar uma grande correlação com a variável explicativa - em outras palavras, rejeitar a hipótese nula (\(\beta_1=0\)).</p>
                    <p>Caso ainda precise de mais detalhes sobre o p-valor, assista o vídeo a seguir:</p>
                    <iframe width="100%" height="515" src="https://www.youtube.com/embed/z-HSsVARNnk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <br>
                    <br>
                    <ul class="justified-list">
                        <li>Como podemos usar a estatística-t para encontrar o p-valor usando a tabela-t (<b>pergunta de prova</b>)?</li>
                    </ul>
                    <p>Quando o p-valor não for fornecido, precisaremos encontrar o seu valor aproximado na tabela-t. Vamos considerar um exemplo com os seguintes dados:</p>
                    <p>\(df = n - k - 1 = 30 - 1 - 1 = 28\)</p>
                    <p>\(estatística-t (|t|) = \frac{\hat{\beta_1}-0}{SE(\hat{\beta_1})}=2,5\)</p>
                    <p>Passo-a-passo:</p>
                    <p>(imagem table-t)</p>
                    <ul class="justified-list list-number">
                        <li>Encontre a linha na tabela-t que corresponde aos graus de liberdade do exemplo (28).</li>
                        <li>Nessa linha, encontre o(s) valor(es) crítico(s) mais próximo da estatística-t fornecida (2,5);</li>
                        <li>Feito isso, basta observar o nível de significância dessa coluna;</li>
                        <li>Agora, precisamos analisar o teste de hipótese, caso o teste de hipótese possua duas caldas, multiplique o valor encontrado no começo da coluna por 2, caso contrário, multiplique por 1. Esse é o valor aproximado do p-valor.</li>
                    </ul>
                    <p>Obs (passo 2): Caso a estatística-t seja muito alta, digamos 5, dificilmente a tabela-t conterá um valor crítico próximo a esse número dados os graus de liberdade (\(df\)), portanto, você pode assumir que o p-valor é muito pequeno. Repare que os valores críticos a direita da coluna são maiores e estão associados a níveis de significância mais baixos.</p>

                    <h4>3. Intervalo de Confiança (CI) e Valor Crítico (\(t^*\))</h4>
                    <p>O intervalo de confiança (CI) estabelece o intervalo em que a hipótese nula de $\beta_1$ deve estar para que seja aceita, dado o nível de significância estabelecido (5%). Como no nosso exemplo a hipótese nula será sempre: \(H_0:{\beta_1}=0\), caso o intervalo de confiança (CI) não contenha 0 (zero), podemos rejeitar a hipótese nula.</p>
                    <p>CI pode ser calculado usando a seguinte fórmula:</p>
                    <p>
                        $$
                        CI = \hat{\beta_1}\pm t^* * SE(\hat{\beta_1})
                        $$
                    </p>
                    <p>\(\hat{\beta_1}\) = estimador do coeficiente de inclinação do modelo de regressão (hipótese alternativa)</p>
                    <p>\(t^*\) = valor crítico t obtido na tabela-t</p>
                    <p>\(SE(\hat{\beta_1})\) = erro padrão do estimador do coeficiente de inclinação do modelo de regressão</p>
                    <p>Vamos fazer um exemplo com os seguintes dados:</p>
                    <ul class="justified-list">
                        <li>Estimador do coeficiente angular (\(\hat{\beta_1}\)) = 2,5</li>
                        <li>Erro padrão do estimador do coeficiente angular (\(SE(\hat{\beta_1})\)) = 0,5</li>
                        <li>Tamanho da amostra (n) = 30</li>
                        <li>Número de variaveis explicativas (k) = 1</li>
                    </ul>
                    <p>Passo-a-passo:</p>
                    <p>1. Com isso, podemos calcular o valor crítico na tabela-t:</p>
                    <p>Para o nível de significância de 5% (como ele não foi informado, podemos assumir \(\alpha=5\%\)) e graus de liberdade \(df = n - k - 1 = 30 - 1 - 1 = 28\), o valor crítico (\(t^*\)) na tabela-t seria de 2,048.</p>
                    <p>2. Agora, basta substituir na fórmula:</p>
                    <p>
                        $$
                            CI = \hat{\beta_1} \pm t^* * SE(\hat{\beta_1})
                        $$
                        $$
                            CI =2,5 \pm 2,048*0,5
                        $$
                        $$
                            CI = 2,5 \pm1,024
                        $$
                        $$
                            CI = (1,476;3,524)
                        $$
                    </p>
                    <p>Interpretação:</p>
                    <ul class="justified-list">
                        <li>Para o nível de significância de 5%, o intervalo de confiança de \(\beta_1\) é (1,476;3,524).</li><br>
                        <li>Como o intervalo não contém zero, podemos rejeitar a hipótese nula \(H_0:{\beta_1}=0\) ao nível de significância de 5%.</li><br>
                        <li>Isso indica que o \(\beta_1\) é significativamente diferente de zero, sugerindo que a relação entre a variável explicativa (\(X_1\)) associada a \(\beta_1\) e a variável dependente (\(Y\)) possui significância estatística.</li><br>
                    </ul>
                </section>
                <section id="qualidade-modelo">
                    <h3>Qualidade do Modelo de Regressão Simples</h3>
                    <p>Ta beleza, povão? (Se tiver achado alguma parte confusa, envie um e-mail para gente)</p>
                    <p>Nesta seção vamos explicar como podemos avaliar a qualidade do modelo de regressão. Preste atenção pois essa matéria também faz parte daqueles “70%” da P1.</p>
                    <p>Vamos começar explicando o coeficiente de determinação (\(R^2\)):</p>

                    <h4>Coeficiente de Determinação (\(R^2\))</h4>
                    <p>O coeficiente de determinação mensura quão bem a variável independente (X) explica a variação na variável dependente (Y), dentro de uma determinada <b>amostra</b> (esse detalhe é importante para entender a estatística F). Essa estatística indica a proporção da variação na variável dependente (Y) que é explicada pela variável explicativa (X). Seu valor varia entre 0 e 1. 0 indica que a variável explicativa (X) não explica a variação na variável dependente (Y), e 1.</p>
                    <p>O \(R^2\) é medido dentro do contexto da amostra, ou seja, amostras diferentes da mesma população podem resultar em coeficientes de determinação diferentes, mas servem como estimadores do \(R^2\) populacional. Quanto maior o R ao quadrado, mais o modelo de regressão simples consegue explicar o que acontece com a variável dependente dentro da população.</p>
                    <p>Nesse caso, como estamos falando de um modelo de regressão simples - com uma unica variável explicativa, o coeficiente de determinação (\(R^2\)) servirá bem esse propósito. Por sua vez, existem uma situção em que o coeficiente de determinação não é recomendado:</p>
                    <p>Quando queremos comparar a qualidade de dois modelos de regressão com quantidades diferentes de variaveis explicativas (X), como por exemplo, um modelo de regressão simples e um modelo de regressão múltiplo.</p>
                    <p>Isso acontece pois sempre que aumentamos o número de variaveis explicativas (k), o \(R^2\) será positivamente impactado, mesmo que as variaveis explicativas (X) adicionadas não ajudem a explicar a variação da variável dependente (Y).</p>
                    <p>Obs: Na P1, não precisamos “ajustar” o coeficiente de determinação. Vamos “ajustar” o R ao quadrado pela “quantidade de variaveis explicativas” (ou k) na seção de Resumo P2.</p>
                    <p>Segue a fórmula de calculo do \(R^2\):</p>
                    <p>
                        $$
                            R^2=1-\frac{SQR}{SQT}
                        $$
                        ou
                        $$
                            R^2=\frac{SQE}{SQT}
                        $$
                    </p>
                    <p>\(R^2\) = coeficiente de determinação;</p>
                    <p>\(SQT\) = soma total dos quadrados da variável dependente (y) (SST em inglês) - soma da diferença entre o valor observado de y e a sua média amostral \(\bar{y}\) ao quadrado;</p>
                    <p>\(SQE\) = soma dos quadrados <b>explicados</b> pelo modelo de regressão (SSR em inglês) - soma da diferença entre o valor estimado pelo modelo de regressão \(\hat{y}\) para aquela observação e a média amostral \(\bar{y}\) ao quadrado;</p>
                    <p>\(SQR\) = soma dos quadrados dos <b>resíduos</b> da variável dependente (y) ou soma dos quadrados dos erros (SSE em inglês) - soma da diferença entre o valor observado de y e o valor estimado pelo modelo \(\hat{y}\) ao quadrado.</p>
                    <p>A fórmula é simples, porém, o que essa razão representa na prática?</p>
                    <p>O SQR representa a variabilidade de Y que não pode ser explicada pelas variáveis explicativas do modelo - o residual (u), portanto, quanto maior o SQR relativamente ao SQT, maior será a proporção da variação da variável dependente (Y) que <b>não</b> pode ser explicada pelo modelo de regressão. Essa razão “menos 1” fornece quanto a variabilidade total da variável dependente (Y) é explicada pelas variaveis explicativas do modelo.</p>
                    <p>Vamos aproveitar para entender os conceitos adjacentes a \(R^2\), os “SQs”.</p>

                    <h4>Decomposição da Soma Total dos Quadrados (”SQs”)</h4>
                    <p>No contexto do modelo de regressão, os “SQs” são um conjunto de estatísticas que ajudam a medir a efetividade do modelo de regressão. Sempre serão calculados com base nas observações das variaveis dependentes (\(y\)) da amostra.</p>
            
                    <p>A fórmula do Coeficiente de Determinação (\(R^2\)) está intimamente ligada ao SQT, portanto, os dois possuem interpretações parecidas. Porém, diferente do \(R^2\) que está preocupado em explicar a proporção da variável dependente que é explicada pelo modelo de regressão, o SQT está preocupado em determinar a variação total da variável dependente (y) que precisa ser explicada pelo modelo de regressão. Como você pode ver na fórmula abaixo, o SQT pode ser calculado pela soma de SQE e SQR, onde SQE representa a variação que pode ser explicada pelo modelo de regressão e SQR representa a parte que não pode ser explicada pelo modelo - o residual (u).</p>
                    <p>
                        $$
                        SQT=SQE+SQR
                        $$
                    </p>
                    <ul class="justified-list">
                        <li>Soma Total dos Quadrados (SQT)</li><br>
                        <p>Se por acaso for necessário calcular o SQT usando as observações da amostra (isso não costuma acontecer), sem usar a fórmula acima, ela pode ser calculado pela soma da diferença das variaveis dependentes (\(y\)) em relação a sua média (\(\bar{y}\)) elevado ao quadrado:</p>
                        <p>
                            $$
                                SQT = \sum^n_{i=1}(y_i-\bar{y})^2
                            $$
                        </p>
                        <p>Logo, quanto maior o SQT, maior a variabilidade da amostra em relação a média. Portanto, o SQT pode variar de 0 (zero) a mais infinito. </p>
                        <p>Imagine um “gráfico de bolinhas” (scatter chart) com as variaveis dependentes (\(y\)), agora desenhe uma linha horizontal que representa a média das variaveis dependentes da amostra (\(\bar{y}\)). A distância de cada observação para essa linha horizontal representa a variação total dos dados (SQT).</p>

                        <li>Soma dos Quadrados Explicada pela Regressão (SQE)</li>
                        <p>Quantifica quanto da variação total de \(y\) é capturada pelo modelo de regressão.</p>
                        <p>
                            $$
                                SQE=\sum^n_{i=1}(\hat{y}_i - \bar{y})^2
                            $$
                        </p>
                        <p>Um SQE maior relativo ao SQT sugere um modelo mais ajustado. Talvez você não tenha entendido o valor de \(\hat{y}_i\), mas ele é calculado para cada linha da sua tabela (amostra) usando o valor de \(x_1\) e o modelo de regressão criado: \(\hat{y}_i=\beta_0+\beta_1x_i\).</p>
                        <p>A distância de cada ponto de dados da linha do modelo de regressão representa a variação que não é explicada pelo modelo - o residual (SQR).</p>

                        <li>Soma dos Quadrados dos Resíduos (SQR)</li>
                        <p>Quantifica a variabilidade total de \(y\) que não é explicada pelo modelo de regressão.</p>
                        <p>
                            $$
                                SQE=\sum^n_{i=1}(y_i-\hat{y}_i)^2
                            $$
                        </p>
                        <p>Um SQR maior sugere um encaixe <b>menor</b> do modelo de regressão com os dados da amostra.</p>
                        <p>A distância da linha de regressão e a linha de média representa a variação que é explicada pelo modelo (SQE).</p>
                    </ul>
                </section>
            </section>
        </main>
        <aside class="side-menu right">
            <h2>Important Notes & News</h2>
            <!-- Notes and news content here -->
        </aside>
    </div>
    <footer>
        <p>&copy; 2024 Professor Diego Braga</p>
    </footer>
    <script src="..\static\script.js"></script>
</body>
</html>
